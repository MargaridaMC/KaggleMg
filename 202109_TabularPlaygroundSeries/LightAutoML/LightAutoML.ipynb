{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa715606-032c-43ab-9e33-c346d7d1e694",
   "metadata": {},
   "source": [
    "Code copied from: https://www.kaggle.com/alexryzhkov/n3-tps-april-21-lightautoml-starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3165b89c-761f-4924-bbce-fbe0a5fc75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Standard python libraries\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.dataset.roles import DatetimeRole\n",
    "from lightautoml.tasks import Task\n",
    "# from lightautoml.utils.profiler import Profiler # Deprecated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2829e57b-e24d-4d1a-824a-f6dcf4cf3168",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18672786-05bc-4d38-992a-adf7c4e52f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 4 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 8*3600 # Time in seconds for automl run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc01ebd0-4803-4286-840e-9157914a6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc63a4-a7c3-4d17-9c0c-c06d8fac233a",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39fe88e0-9d95-4a07-964a-0939597b4532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f111</th>\n",
       "      <th>f112</th>\n",
       "      <th>f113</th>\n",
       "      <th>f114</th>\n",
       "      <th>f115</th>\n",
       "      <th>f116</th>\n",
       "      <th>f117</th>\n",
       "      <th>f118</th>\n",
       "      <th>claim</th>\n",
       "      <th>count_na</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10859</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>-37.566</td>\n",
       "      <td>0.017364</td>\n",
       "      <td>0.28915</td>\n",
       "      <td>-10.25100</td>\n",
       "      <td>135.12</td>\n",
       "      <td>168900.0</td>\n",
       "      <td>3.992400e+14</td>\n",
       "      <td>86.489</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7482</td>\n",
       "      <td>1.90960</td>\n",
       "      <td>-7.11570</td>\n",
       "      <td>4378.80</td>\n",
       "      <td>1.2096</td>\n",
       "      <td>8.613400e+14</td>\n",
       "      <td>140.100000</td>\n",
       "      <td>1.01770</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10090</td>\n",
       "      <td>0.299610</td>\n",
       "      <td>11822.000</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.45970</td>\n",
       "      <td>-0.83733</td>\n",
       "      <td>1721.90</td>\n",
       "      <td>119810.0</td>\n",
       "      <td>3.874100e+15</td>\n",
       "      <td>9953.600</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1684</td>\n",
       "      <td>0.34808</td>\n",
       "      <td>4.14200</td>\n",
       "      <td>913.23</td>\n",
       "      <td>1.2464</td>\n",
       "      <td>7.575100e+15</td>\n",
       "      <td>1861.000000</td>\n",
       "      <td>0.28359</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.17803</td>\n",
       "      <td>-0.006980</td>\n",
       "      <td>907.270</td>\n",
       "      <td>0.272140</td>\n",
       "      <td>0.45948</td>\n",
       "      <td>0.17327</td>\n",
       "      <td>2298.00</td>\n",
       "      <td>360650.0</td>\n",
       "      <td>1.224500e+13</td>\n",
       "      <td>15827.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2042</td>\n",
       "      <td>0.26290</td>\n",
       "      <td>8.13120</td>\n",
       "      <td>45119.00</td>\n",
       "      <td>1.1764</td>\n",
       "      <td>3.218100e+14</td>\n",
       "      <td>3838.200000</td>\n",
       "      <td>0.40690</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15236</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>780.100</td>\n",
       "      <td>0.025179</td>\n",
       "      <td>0.51947</td>\n",
       "      <td>7.49140</td>\n",
       "      <td>112.51</td>\n",
       "      <td>259490.0</td>\n",
       "      <td>7.781400e+13</td>\n",
       "      <td>-36.837</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0694</td>\n",
       "      <td>0.79631</td>\n",
       "      <td>-16.33600</td>\n",
       "      <td>4952.40</td>\n",
       "      <td>1.1784</td>\n",
       "      <td>4.533000e+12</td>\n",
       "      <td>4889.100000</td>\n",
       "      <td>0.51486</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.11623</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>-109.150</td>\n",
       "      <td>0.297910</td>\n",
       "      <td>0.34490</td>\n",
       "      <td>-0.40932</td>\n",
       "      <td>2538.90</td>\n",
       "      <td>65332.0</td>\n",
       "      <td>1.907200e+15</td>\n",
       "      <td>144.120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5298</td>\n",
       "      <td>1.14640</td>\n",
       "      <td>-0.43124</td>\n",
       "      <td>3856.50</td>\n",
       "      <td>1.4830</td>\n",
       "      <td>-8.991300e+12</td>\n",
       "      <td>3959.204669</td>\n",
       "      <td>0.23049</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2         f3        f4       f5        f6       f7  \\\n",
       "id                                                                       \n",
       "0   0.10859  0.004314    -37.566  0.017364  0.28915 -10.25100   135.12   \n",
       "1   0.10090  0.299610  11822.000  0.276500  0.45970  -0.83733  1721.90   \n",
       "2   0.17803 -0.006980    907.270  0.272140  0.45948   0.17327  2298.00   \n",
       "3   0.15236  0.007259    780.100  0.025179  0.51947   7.49140   112.51   \n",
       "4   0.11623  0.502900   -109.150  0.297910  0.34490  -0.40932  2538.90   \n",
       "\n",
       "          f8            f9        f10  ...    f111     f112      f113  \\\n",
       "id                                     ...                              \n",
       "0   168900.0  3.992400e+14     86.489  ...  1.7482  1.90960  -7.11570   \n",
       "1   119810.0  3.874100e+15   9953.600  ...  4.1684  0.34808   4.14200   \n",
       "2   360650.0  1.224500e+13  15827.000  ...  1.2042  0.26290   8.13120   \n",
       "3   259490.0  7.781400e+13    -36.837  ...  2.0694  0.79631 -16.33600   \n",
       "4    65332.0  1.907200e+15    144.120  ...  1.5298  1.14640  -0.43124   \n",
       "\n",
       "        f114    f115          f116         f117     f118  claim  count_na  \n",
       "id                                                                         \n",
       "0    4378.80  1.2096  8.613400e+14   140.100000  1.01770      1         1  \n",
       "1     913.23  1.2464  7.575100e+15  1861.000000  0.28359      0         0  \n",
       "2   45119.00  1.1764  3.218100e+14  3838.200000  0.40690      1         5  \n",
       "3    4952.40  1.1784  4.533000e+12  4889.100000  0.51486      1         2  \n",
       "4    3856.50  1.4830 -8.991300e+12  3959.204669  0.23049      1         8  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('../Data/train_w_nan.csv', index_col = 0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67b6bd41-d593-4b09-b777-dc62291a9833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f110</th>\n",
       "      <th>f111</th>\n",
       "      <th>f112</th>\n",
       "      <th>f113</th>\n",
       "      <th>f114</th>\n",
       "      <th>f115</th>\n",
       "      <th>f116</th>\n",
       "      <th>f117</th>\n",
       "      <th>f118</th>\n",
       "      <th>count_na</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>957919</th>\n",
       "      <td>0.165850</td>\n",
       "      <td>0.487050</td>\n",
       "      <td>1295.00</td>\n",
       "      <td>0.02310</td>\n",
       "      <td>0.31900</td>\n",
       "      <td>0.90188</td>\n",
       "      <td>573.29</td>\n",
       "      <td>3743.7</td>\n",
       "      <td>2.705700e+12</td>\n",
       "      <td>6221.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.1890</td>\n",
       "      <td>2.0655</td>\n",
       "      <td>0.430880</td>\n",
       "      <td>-10.7410</td>\n",
       "      <td>81606.0</td>\n",
       "      <td>1.1940</td>\n",
       "      <td>1.980400e+14</td>\n",
       "      <td>2017.1</td>\n",
       "      <td>0.46357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957920</th>\n",
       "      <td>0.129650</td>\n",
       "      <td>0.373480</td>\n",
       "      <td>1763.00</td>\n",
       "      <td>0.72884</td>\n",
       "      <td>0.33247</td>\n",
       "      <td>-1.26310</td>\n",
       "      <td>875.55</td>\n",
       "      <td>554370.0</td>\n",
       "      <td>5.955700e+14</td>\n",
       "      <td>934.430</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.6342</td>\n",
       "      <td>1.5736</td>\n",
       "      <td>-1.071200</td>\n",
       "      <td>11.8320</td>\n",
       "      <td>90114.0</td>\n",
       "      <td>1.1507</td>\n",
       "      <td>4.388000e+16</td>\n",
       "      <td>6638.9</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957921</th>\n",
       "      <td>0.120190</td>\n",
       "      <td>0.445210</td>\n",
       "      <td>736.26</td>\n",
       "      <td>0.04615</td>\n",
       "      <td>0.29605</td>\n",
       "      <td>0.31665</td>\n",
       "      <td>2659.50</td>\n",
       "      <td>317140.0</td>\n",
       "      <td>3.977800e+14</td>\n",
       "      <td>131.810</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.7800</td>\n",
       "      <td>2.1364</td>\n",
       "      <td>-1.931200</td>\n",
       "      <td>-3.2804</td>\n",
       "      <td>37739.0</td>\n",
       "      <td>1.1548</td>\n",
       "      <td>1.718100e+14</td>\n",
       "      <td>5844.0</td>\n",
       "      <td>0.13797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957922</th>\n",
       "      <td>0.054008</td>\n",
       "      <td>0.395960</td>\n",
       "      <td>996.14</td>\n",
       "      <td>0.85934</td>\n",
       "      <td>0.36678</td>\n",
       "      <td>-0.17060</td>\n",
       "      <td>386.56</td>\n",
       "      <td>325680.0</td>\n",
       "      <td>-3.432200e+13</td>\n",
       "      <td>-26.473</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.4162</td>\n",
       "      <td>1.5199</td>\n",
       "      <td>-0.011633</td>\n",
       "      <td>1.3840</td>\n",
       "      <td>26849.0</td>\n",
       "      <td>1.1490</td>\n",
       "      <td>2.138800e+17</td>\n",
       "      <td>6173.3</td>\n",
       "      <td>0.32910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957923</th>\n",
       "      <td>0.079947</td>\n",
       "      <td>-0.006919</td>\n",
       "      <td>10574.00</td>\n",
       "      <td>0.34845</td>\n",
       "      <td>0.45008</td>\n",
       "      <td>-1.84200</td>\n",
       "      <td>3027.00</td>\n",
       "      <td>428150.0</td>\n",
       "      <td>9.291500e+11</td>\n",
       "      <td>5999.400</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.6300</td>\n",
       "      <td>3.7387</td>\n",
       "      <td>0.757080</td>\n",
       "      <td>-4.9405</td>\n",
       "      <td>50336.0</td>\n",
       "      <td>1.2488</td>\n",
       "      <td>2.151300e+17</td>\n",
       "      <td>2250.1</td>\n",
       "      <td>0.33796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1        f2        f3       f4       f5       f6       f7  \\\n",
       "id                                                                         \n",
       "957919  0.165850  0.487050   1295.00  0.02310  0.31900  0.90188   573.29   \n",
       "957920  0.129650  0.373480   1763.00  0.72884  0.33247 -1.26310   875.55   \n",
       "957921  0.120190  0.445210    736.26  0.04615  0.29605  0.31665  2659.50   \n",
       "957922  0.054008  0.395960    996.14  0.85934  0.36678 -0.17060   386.56   \n",
       "957923  0.079947 -0.006919  10574.00  0.34845  0.45008 -1.84200  3027.00   \n",
       "\n",
       "              f8            f9       f10  ...     f110    f111      f112  \\\n",
       "id                                        ...                              \n",
       "957919    3743.7  2.705700e+12  6221.000  ... -22.1890  2.0655  0.430880   \n",
       "957920  554370.0  5.955700e+14   934.430  ...  -1.6342  1.5736 -1.071200   \n",
       "957921  317140.0  3.977800e+14   131.810  ... -32.7800  2.1364 -1.931200   \n",
       "957922  325680.0 -3.432200e+13   -26.473  ...  -2.4162  1.5199 -0.011633   \n",
       "957923  428150.0  9.291500e+11  5999.400  ... -18.6300  3.7387  0.757080   \n",
       "\n",
       "           f113     f114    f115          f116    f117     f118  count_na  \n",
       "id                                                                         \n",
       "957919 -10.7410  81606.0  1.1940  1.980400e+14  2017.1  0.46357         1  \n",
       "957920  11.8320  90114.0  1.1507  4.388000e+16  6638.9  0.28125         0  \n",
       "957921  -3.2804  37739.0  1.1548  1.718100e+14  5844.0  0.13797         1  \n",
       "957922   1.3840  26849.0  1.1490  2.138800e+17  6173.3  0.32910         0  \n",
       "957923  -4.9405  50336.0  1.2488  2.151300e+17  2250.1  0.33796         0  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('../Data/test_w_nan.csv', index_col = 0)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "282fd2c2-38cd-4438-b6d3-79aa95845fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>957919</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957920</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957921</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957922</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957923</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        claim\n",
       "id           \n",
       "957919    0.5\n",
       "957920    0.5\n",
       "957921    0.5\n",
       "957922    0.5\n",
       "957923    0.5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../Data/sample_solution.csv', index_col = 0)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d758aaa-d671-4489-a65a-c1721d5e5b34",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc602312-60ed-4f64-92a1-a00f859f8a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "task = Task('binary', loss = 'logloss', metric = roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f70742b-812d-4f9d-a267-62d05c8c3063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start automl preset with listed constraints:\n",
      "- time: 28800 seconds\n",
      "- cpus: 4 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (957919, 120)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 28768.941902160645 secs\n",
      "Start fitting Selector_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Selector_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.509904\tvalid's Opt metric: 0.810416\n",
      "[200]\tvalid's binary_logloss: 0.509196\tvalid's Opt metric: 0.811915\n",
      "[300]\tvalid's binary_logloss: 0.509489\tvalid's Opt metric: 0.811735\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid's binary_logloss: 0.509193\tvalid's Opt metric: 0.811914\n",
      "Selector_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.510403\tvalid's Opt metric: 0.810488\n",
      "[200]\tvalid's binary_logloss: 0.509028\tvalid's Opt metric: 0.812093\n",
      "[300]\tvalid's binary_logloss: 0.509223\tvalid's Opt metric: 0.812048\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid's binary_logloss: 0.509016\tvalid's Opt metric: 0.812132\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.50968\tvalid's Opt metric: 0.811704\n",
      "[200]\tvalid's binary_logloss: 0.508331\tvalid's Opt metric: 0.812653\n",
      "[300]\tvalid's binary_logloss: 0.508393\tvalid's Opt metric: 0.812807\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid's binary_logloss: 0.508251\tvalid's Opt metric: 0.812837\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.510621\tvalid's Opt metric: 0.810898\n",
      "[200]\tvalid's binary_logloss: 0.509293\tvalid's Opt metric: 0.81209\n",
      "[300]\tvalid's binary_logloss: 0.509436\tvalid's Opt metric: 0.812104\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid's binary_logloss: 0.509181\tvalid's Opt metric: 0.812315\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.511372\tvalid's Opt metric: 0.810404\n",
      "[200]\tvalid's binary_logloss: 0.510117\tvalid's Opt metric: 0.811782\n",
      "[300]\tvalid's binary_logloss: 0.510082\tvalid's Opt metric: 0.812044\n",
      "Early stopping, best iteration is:\n",
      "[228]\tvalid's binary_logloss: 0.51\tvalid's Opt metric: 0.812045\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.511301\tvalid's Opt metric: 0.810037\n",
      "[200]\tvalid's binary_logloss: 0.510128\tvalid's Opt metric: 0.811136\n",
      "[300]\tvalid's binary_logloss: 0.51027\tvalid's Opt metric: 0.811126\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid's binary_logloss: 0.510047\tvalid's Opt metric: 0.81138\n",
      "Lvl_0_Pipe_0_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 3547.9800546819506 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.510572\tvalid's Opt metric: 0.810236\n",
      "[200]\tvalid's binary_logloss: 0.509213\tvalid's Opt metric: 0.811724\n",
      "[300]\tvalid's binary_logloss: 0.509317\tvalid's Opt metric: 0.811868\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid's binary_logloss: 0.509188\tvalid's Opt metric: 0.811828\n",
      "Lvl_0_Pipe_0_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_0_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.513721\tvalid's Opt metric: 0.810734\n",
      "[200]\tvalid's binary_logloss: 0.508953\tvalid's Opt metric: 0.812483\n",
      "[300]\tvalid's binary_logloss: 0.508853\tvalid's Opt metric: 0.812732\n",
      "Early stopping, best iteration is:\n",
      "[294]\tvalid's binary_logloss: 0.508836\tvalid's Opt metric: 0.81276\n",
      "Lvl_0_Pipe_0_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_0_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.513721\tvalid's Opt metric: 0.810734\n",
      "[200]\tvalid's binary_logloss: 0.508953\tvalid's Opt metric: 0.812483\n",
      "[300]\tvalid's binary_logloss: 0.508853\tvalid's Opt metric: 0.812732\n",
      "Early stopping, best iteration is:\n",
      "[294]\tvalid's binary_logloss: 0.508836\tvalid's Opt metric: 0.81276\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.51291\tvalid's Opt metric: 0.811992\n",
      "[200]\tvalid's binary_logloss: 0.508066\tvalid's Opt metric: 0.813386\n",
      "[300]\tvalid's binary_logloss: 0.50788\tvalid's Opt metric: 0.813724\n",
      "Early stopping, best iteration is:\n",
      "[274]\tvalid's binary_logloss: 0.507815\tvalid's Opt metric: 0.813846\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.513711\tvalid's Opt metric: 0.811358\n",
      "[200]\tvalid's binary_logloss: 0.509116\tvalid's Opt metric: 0.812427\n",
      "[300]\tvalid's binary_logloss: 0.50887\tvalid's Opt metric: 0.812976\n",
      "[400]\tvalid's binary_logloss: 0.50886\tvalid's Opt metric: 0.813022\n",
      "Early stopping, best iteration is:\n",
      "[313]\tvalid's binary_logloss: 0.508829\tvalid's Opt metric: 0.813061\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.51428\tvalid's Opt metric: 0.811044\n",
      "[200]\tvalid's binary_logloss: 0.509676\tvalid's Opt metric: 0.81256\n",
      "[300]\tvalid's binary_logloss: 0.509477\tvalid's Opt metric: 0.812872\n",
      "[400]\tvalid's binary_logloss: 0.50959\tvalid's Opt metric: 0.81277\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid's binary_logloss: 0.509421\tvalid's Opt metric: 0.813018\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's binary_logloss: 0.514406\tvalid's Opt metric: 0.810049\n",
      "[200]\tvalid's binary_logloss: 0.509938\tvalid's Opt metric: 0.811382\n",
      "[300]\tvalid's binary_logloss: 0.509768\tvalid's Opt metric: 0.811957\n",
      "[400]\tvalid's binary_logloss: 0.509743\tvalid's Opt metric: 0.812237\n",
      "Early stopping, best iteration is:\n",
      "[339]\tvalid's binary_logloss: 0.509657\tvalid's Opt metric: 0.812287\n",
      "Lvl_0_Pipe_0_Mod_1_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_0_Mod_2_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_2_CatBoost =====\n",
      "\n",
      "0:\tlearn: 0.6738529\ttest: 0.6738260\tbest: 0.6738260 (0)\ttotal: 891ms\tremaining: 44m 30s\n",
      "100:\tlearn: 0.5117355\ttest: 0.5116450\tbest: 0.5116450 (100)\ttotal: 1m 22s\tremaining: 39m 26s\n",
      "200:\tlearn: 0.5103955\ttest: 0.5106637\tbest: 0.5106637 (200)\ttotal: 2m 42s\tremaining: 37m 46s\n",
      "300:\tlearn: 0.5093801\ttest: 0.5100027\tbest: 0.5100027 (300)\ttotal: 4m\tremaining: 35m 59s\n",
      "400:\tlearn: 0.5084560\ttest: 0.5094948\tbest: 0.5094948 (400)\ttotal: 5m 27s\tremaining: 35m 22s\n",
      "500:\tlearn: 0.5076809\ttest: 0.5091626\tbest: 0.5091626 (500)\ttotal: 6m 49s\tremaining: 34m 3s\n",
      "600:\tlearn: 0.5069937\ttest: 0.5088938\tbest: 0.5088932 (599)\ttotal: 8m 31s\tremaining: 34m\n",
      "700:\tlearn: 0.5063503\ttest: 0.5086868\tbest: 0.5086868 (700)\ttotal: 9m 46s\tremaining: 32m 3s\n",
      "800:\tlearn: 0.5057330\ttest: 0.5085537\tbest: 0.5085537 (800)\ttotal: 11m 18s\tremaining: 31m 2s\n",
      "900:\tlearn: 0.5051638\ttest: 0.5084162\tbest: 0.5084156 (898)\ttotal: 12m 58s\tremaining: 30m 12s\n",
      "1000:\tlearn: 0.5045888\ttest: 0.5083277\tbest: 0.5083277 (1000)\ttotal: 14m 38s\tremaining: 29m 15s\n",
      "1100:\tlearn: 0.5040482\ttest: 0.5082365\tbest: 0.5082365 (1100)\ttotal: 15m 59s\tremaining: 27m 35s\n",
      "1200:\tlearn: 0.5035262\ttest: 0.5081482\tbest: 0.5081482 (1200)\ttotal: 17m 44s\tremaining: 26m 34s\n",
      "1300:\tlearn: 0.5030029\ttest: 0.5080913\tbest: 0.5080913 (1300)\ttotal: 19m 17s\tremaining: 25m 11s\n",
      "1400:\tlearn: 0.5024866\ttest: 0.5080551\tbest: 0.5080551 (1400)\ttotal: 19m 55s\tremaining: 22m 43s\n",
      "1500:\tlearn: 0.5019763\ttest: 0.5079950\tbest: 0.5079886 (1496)\ttotal: 20m 13s\tremaining: 20m 11s\n",
      "1600:\tlearn: 0.5014707\ttest: 0.5079529\tbest: 0.5079529 (1600)\ttotal: 20m 31s\tremaining: 17m 56s\n",
      "1700:\tlearn: 0.5009713\ttest: 0.5079123\tbest: 0.5079118 (1698)\ttotal: 20m 50s\tremaining: 15m 54s\n",
      "1800:\tlearn: 0.5004839\ttest: 0.5078919\tbest: 0.5078913 (1798)\ttotal: 21m 8s\tremaining: 14m 4s\n",
      "1900:\tlearn: 0.4999853\ttest: 0.5078699\tbest: 0.5078660 (1891)\ttotal: 21m 26s\tremaining: 12m 23s\n",
      "2000:\tlearn: 0.4995044\ttest: 0.5078378\tbest: 0.5078378 (2000)\ttotal: 21m 44s\tremaining: 10m 51s\n",
      "2100:\tlearn: 0.4990237\ttest: 0.5078022\tbest: 0.5078014 (2099)\ttotal: 22m 3s\tremaining: 9m 26s\n",
      "2200:\tlearn: 0.4985281\ttest: 0.5077583\tbest: 0.5077579 (2198)\ttotal: 22m 21s\tremaining: 8m 7s\n",
      "2300:\tlearn: 0.4980579\ttest: 0.5077397\tbest: 0.5077362 (2281)\ttotal: 22m 40s\tremaining: 6m 53s\n",
      "2400:\tlearn: 0.4975976\ttest: 0.5077272\tbest: 0.5077251 (2362)\ttotal: 22m 59s\tremaining: 5m 44s\n",
      "2500:\tlearn: 0.4971304\ttest: 0.5077191\tbest: 0.5077141 (2477)\ttotal: 23m 23s\tremaining: 4m 39s\n",
      "2600:\tlearn: 0.4966705\ttest: 0.5077134\tbest: 0.5077083 (2553)\ttotal: 23m 41s\tremaining: 3m 38s\n",
      "2700:\tlearn: 0.4961973\ttest: 0.5076938\tbest: 0.5076857 (2682)\ttotal: 24m\tremaining: 2m 39s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.5076856877\n",
      "bestIteration = 2682\n",
      "\n",
      "Shrink model to first 2683 iterations.\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_2_CatBoost =====\n",
      "\n",
      "0:\tlearn: 0.6738670\ttest: 0.6738055\tbest: 0.6738055 (0)\ttotal: 234ms\tremaining: 11m 42s\n",
      "100:\tlearn: 0.5119588\ttest: 0.5110434\tbest: 0.5110434 (100)\ttotal: 19.6s\tremaining: 9m 22s\n",
      "200:\tlearn: 0.5106311\ttest: 0.5099468\tbest: 0.5099468 (200)\ttotal: 37.5s\tremaining: 8m 42s\n",
      "300:\tlearn: 0.5096280\ttest: 0.5092350\tbest: 0.5092350 (300)\ttotal: 55.4s\tremaining: 8m 16s\n",
      "400:\tlearn: 0.5087044\ttest: 0.5086736\tbest: 0.5086736 (400)\ttotal: 1m 13s\tremaining: 7m 55s\n",
      "500:\tlearn: 0.5079426\ttest: 0.5083429\tbest: 0.5083429 (500)\ttotal: 1m 30s\tremaining: 7m 33s\n",
      "600:\tlearn: 0.5072454\ttest: 0.5080811\tbest: 0.5080811 (600)\ttotal: 1m 48s\tremaining: 7m 14s\n",
      "700:\tlearn: 0.5066042\ttest: 0.5078544\tbest: 0.5078544 (700)\ttotal: 2m 6s\tremaining: 6m 55s\n",
      "800:\tlearn: 0.5059878\ttest: 0.5076930\tbest: 0.5076930 (800)\ttotal: 2m 24s\tremaining: 6m 37s\n",
      "900:\tlearn: 0.5054210\ttest: 0.5075518\tbest: 0.5075518 (900)\ttotal: 2m 43s\tremaining: 6m 20s\n",
      "1000:\tlearn: 0.5048801\ttest: 0.5074716\tbest: 0.5074708 (995)\ttotal: 3m 1s\tremaining: 6m 2s\n",
      "1100:\tlearn: 0.5043299\ttest: 0.5073802\tbest: 0.5073792 (1096)\ttotal: 3m 19s\tremaining: 5m 44s\n",
      "1200:\tlearn: 0.5038080\ttest: 0.5073030\tbest: 0.5073013 (1197)\ttotal: 3m 38s\tremaining: 5m 26s\n",
      "1300:\tlearn: 0.5032830\ttest: 0.5072347\tbest: 0.5072347 (1300)\ttotal: 3m 56s\tremaining: 5m 8s\n",
      "1400:\tlearn: 0.5027734\ttest: 0.5071847\tbest: 0.5071845 (1399)\ttotal: 4m 14s\tremaining: 4m 50s\n",
      "1500:\tlearn: 0.5022676\ttest: 0.5071041\tbest: 0.5071041 (1499)\ttotal: 4m 33s\tremaining: 4m 33s\n",
      "1600:\tlearn: 0.5017757\ttest: 0.5070733\tbest: 0.5070724 (1591)\ttotal: 4m 51s\tremaining: 4m 14s\n",
      "1700:\tlearn: 0.5012848\ttest: 0.5070395\tbest: 0.5070389 (1698)\ttotal: 5m 10s\tremaining: 3m 57s\n",
      "1800:\tlearn: 0.5007959\ttest: 0.5070306\tbest: 0.5070306 (1800)\ttotal: 5m 28s\tremaining: 3m 38s\n",
      "1900:\tlearn: 0.5003203\ttest: 0.5069843\tbest: 0.5069826 (1897)\ttotal: 5m 47s\tremaining: 3m 20s\n",
      "2000:\tlearn: 0.4998384\ttest: 0.5069532\tbest: 0.5069503 (1990)\ttotal: 6m 5s\tremaining: 3m 2s\n",
      "2100:\tlearn: 0.4993661\ttest: 0.5069328\tbest: 0.5069288 (2091)\ttotal: 6m 24s\tremaining: 2m 44s\n",
      "2200:\tlearn: 0.4988940\ttest: 0.5069073\tbest: 0.5069073 (2200)\ttotal: 6m 42s\tremaining: 2m 26s\n",
      "2300:\tlearn: 0.4984169\ttest: 0.5069029\tbest: 0.5068968 (2267)\ttotal: 7m 1s\tremaining: 2m 7s\n",
      "2400:\tlearn: 0.4979523\ttest: 0.5068824\tbest: 0.5068807 (2398)\ttotal: 7m 19s\tremaining: 1m 49s\n",
      "2500:\tlearn: 0.4974846\ttest: 0.5068322\tbest: 0.5068312 (2499)\ttotal: 7m 38s\tremaining: 1m 31s\n",
      "2600:\tlearn: 0.4970207\ttest: 0.5068257\tbest: 0.5068243 (2598)\ttotal: 7m 56s\tremaining: 1m 13s\n",
      "2700:\tlearn: 0.4965592\ttest: 0.5068076\tbest: 0.5067980 (2656)\ttotal: 8m 15s\tremaining: 54.8s\n",
      "2800:\tlearn: 0.4960921\ttest: 0.5067866\tbest: 0.5067841 (2795)\ttotal: 8m 33s\tremaining: 36.5s\n",
      "2900:\tlearn: 0.4956351\ttest: 0.5067775\tbest: 0.5067690 (2876)\ttotal: 8m 52s\tremaining: 18.2s\n",
      "2999:\tlearn: 0.4951697\ttest: 0.5067659\tbest: 0.5067603 (2952)\ttotal: 9m 10s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5067603095\n",
      "bestIteration = 2952\n",
      "\n",
      "Shrink model to first 2953 iterations.\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_2_CatBoost =====\n",
      "\n",
      "0:\tlearn: 0.6738452\ttest: 0.6738573\tbest: 0.6738573 (0)\ttotal: 215ms\tremaining: 10m 45s\n",
      "100:\tlearn: 0.5116816\ttest: 0.5118905\tbest: 0.5118905 (100)\ttotal: 19.7s\tremaining: 9m 26s\n",
      "200:\tlearn: 0.5103322\ttest: 0.5108978\tbest: 0.5108978 (200)\ttotal: 37.6s\tremaining: 8m 44s\n",
      "300:\tlearn: 0.5093527\ttest: 0.5102337\tbest: 0.5102337 (300)\ttotal: 55.2s\tremaining: 8m 15s\n",
      "400:\tlearn: 0.5084039\ttest: 0.5097096\tbest: 0.5097096 (400)\ttotal: 1m 13s\tremaining: 7m 53s\n",
      "500:\tlearn: 0.5076334\ttest: 0.5093787\tbest: 0.5093787 (500)\ttotal: 1m 30s\tremaining: 7m 33s\n",
      "600:\tlearn: 0.5069416\ttest: 0.5091436\tbest: 0.5091436 (600)\ttotal: 1m 49s\tremaining: 7m 15s\n",
      "700:\tlearn: 0.5062835\ttest: 0.5089517\tbest: 0.5089517 (700)\ttotal: 2m 7s\tremaining: 6m 56s\n",
      "800:\tlearn: 0.5056878\ttest: 0.5088080\tbest: 0.5088080 (800)\ttotal: 2m 24s\tremaining: 6m 37s\n",
      "900:\tlearn: 0.5051088\ttest: 0.5086904\tbest: 0.5086897 (899)\ttotal: 2m 43s\tremaining: 6m 19s\n",
      "1000:\tlearn: 0.5045496\ttest: 0.5086103\tbest: 0.5086100 (998)\ttotal: 3m 1s\tremaining: 6m 2s\n",
      "1100:\tlearn: 0.5040016\ttest: 0.5084995\tbest: 0.5084946 (1098)\ttotal: 3m 19s\tremaining: 5m 44s\n",
      "1200:\tlearn: 0.5034507\ttest: 0.5084362\tbest: 0.5084342 (1196)\ttotal: 3m 37s\tremaining: 5m 26s\n",
      "1300:\tlearn: 0.5029308\ttest: 0.5083866\tbest: 0.5083838 (1294)\ttotal: 3m 58s\tremaining: 5m 11s\n",
      "1400:\tlearn: 0.5024256\ttest: 0.5083260\tbest: 0.5083255 (1399)\ttotal: 4m 16s\tremaining: 4m 53s\n",
      "1500:\tlearn: 0.5019095\ttest: 0.5082741\tbest: 0.5082700 (1497)\ttotal: 4m 35s\tremaining: 4m 35s\n",
      "1600:\tlearn: 0.5014104\ttest: 0.5082401\tbest: 0.5082367 (1598)\ttotal: 4m 53s\tremaining: 4m 16s\n",
      "1700:\tlearn: 0.5009278\ttest: 0.5082009\tbest: 0.5082004 (1699)\ttotal: 5m 13s\tremaining: 3m 59s\n",
      "1800:\tlearn: 0.5004338\ttest: 0.5081578\tbest: 0.5081557 (1795)\ttotal: 5m 31s\tremaining: 3m 40s\n",
      "1900:\tlearn: 0.4999570\ttest: 0.5081001\tbest: 0.5080987 (1898)\ttotal: 5m 50s\tremaining: 3m 22s\n",
      "2000:\tlearn: 0.4994727\ttest: 0.5080803\tbest: 0.5080770 (1974)\ttotal: 6m 8s\tremaining: 3m 3s\n",
      "2100:\tlearn: 0.4989926\ttest: 0.5080614\tbest: 0.5080588 (2075)\ttotal: 6m 26s\tremaining: 2m 45s\n",
      "2200:\tlearn: 0.4985054\ttest: 0.5080549\tbest: 0.5080529 (2176)\ttotal: 6m 45s\tremaining: 2m 27s\n",
      "2300:\tlearn: 0.4980302\ttest: 0.5080426\tbest: 0.5080386 (2292)\ttotal: 7m 4s\tremaining: 2m 8s\n",
      "2400:\tlearn: 0.4975535\ttest: 0.5080137\tbest: 0.5080128 (2399)\ttotal: 7m 22s\tremaining: 1m 50s\n",
      "2500:\tlearn: 0.4970804\ttest: 0.5079837\tbest: 0.5079829 (2498)\ttotal: 7m 42s\tremaining: 1m 32s\n",
      "2600:\tlearn: 0.4966105\ttest: 0.5079690\tbest: 0.5079663 (2588)\ttotal: 8m\tremaining: 1m 13s\n",
      "2700:\tlearn: 0.4961497\ttest: 0.5079447\tbest: 0.5079443 (2697)\ttotal: 8m 18s\tremaining: 55.2s\n",
      "2800:\tlearn: 0.4956934\ttest: 0.5079309\tbest: 0.5079297 (2795)\ttotal: 8m 37s\tremaining: 36.7s\n",
      "2900:\tlearn: 0.4952415\ttest: 0.5079401\tbest: 0.5079248 (2803)\ttotal: 8m 56s\tremaining: 18.3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.5079247543\n",
      "bestIteration = 2803\n",
      "\n",
      "Shrink model to first 2804 iterations.\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_2_CatBoost =====\n",
      "\n",
      "0:\tlearn: 0.6738195\ttest: 0.6738624\tbest: 0.6738624 (0)\ttotal: 224ms\tremaining: 11m 11s\n",
      "100:\tlearn: 0.5115426\ttest: 0.5125902\tbest: 0.5125902 (100)\ttotal: 19.7s\tremaining: 9m 25s\n",
      "200:\tlearn: 0.5101879\ttest: 0.5115368\tbest: 0.5115368 (200)\ttotal: 37.5s\tremaining: 8m 41s\n",
      "300:\tlearn: 0.5091729\ttest: 0.5108179\tbest: 0.5108179 (300)\ttotal: 55.3s\tremaining: 8m 16s\n",
      "400:\tlearn: 0.5082252\ttest: 0.5102867\tbest: 0.5102867 (400)\ttotal: 1m 12s\tremaining: 7m 52s\n",
      "500:\tlearn: 0.5074538\ttest: 0.5099397\tbest: 0.5099397 (500)\ttotal: 1m 30s\tremaining: 7m 32s\n",
      "600:\tlearn: 0.5067660\ttest: 0.5097085\tbest: 0.5097085 (600)\ttotal: 1m 48s\tremaining: 7m 14s\n",
      "700:\tlearn: 0.5061273\ttest: 0.5095157\tbest: 0.5095157 (700)\ttotal: 2m 6s\tremaining: 6m 55s\n",
      "800:\tlearn: 0.5055211\ttest: 0.5093720\tbest: 0.5093720 (800)\ttotal: 2m 24s\tremaining: 6m 36s\n",
      "900:\tlearn: 0.5049452\ttest: 0.5092552\tbest: 0.5092552 (900)\ttotal: 2m 42s\tremaining: 6m 19s\n",
      "1000:\tlearn: 0.5043886\ttest: 0.5091532\tbest: 0.5091532 (1000)\ttotal: 3m\tremaining: 6m 1s\n",
      "1100:\tlearn: 0.5038434\ttest: 0.5090600\tbest: 0.5090544 (1096)\ttotal: 3m 18s\tremaining: 5m 42s\n",
      "1200:\tlearn: 0.5033005\ttest: 0.5090028\tbest: 0.5090009 (1195)\ttotal: 3m 37s\tremaining: 5m 26s\n",
      "1300:\tlearn: 0.5027685\ttest: 0.5089392\tbest: 0.5089373 (1299)\ttotal: 4m 4s\tremaining: 5m 19s\n",
      "1400:\tlearn: 0.5022460\ttest: 0.5088705\tbest: 0.5088705 (1400)\ttotal: 4m 27s\tremaining: 5m 5s\n",
      "1500:\tlearn: 0.5017359\ttest: 0.5088538\tbest: 0.5088498 (1493)\ttotal: 4m 53s\tremaining: 4m 52s\n",
      "1600:\tlearn: 0.5012226\ttest: 0.5088195\tbest: 0.5088186 (1599)\ttotal: 5m 18s\tremaining: 4m 37s\n",
      "1700:\tlearn: 0.5007263\ttest: 0.5087918\tbest: 0.5087918 (1700)\ttotal: 5m 37s\tremaining: 4m 18s\n",
      "1800:\tlearn: 0.5002348\ttest: 0.5087704\tbest: 0.5087650 (1778)\ttotal: 5m 57s\tremaining: 3m 57s\n",
      "1900:\tlearn: 0.4997512\ttest: 0.5087478\tbest: 0.5087478 (1900)\ttotal: 6m 23s\tremaining: 3m 41s\n",
      "2000:\tlearn: 0.4992639\ttest: 0.5087274\tbest: 0.5087274 (2000)\ttotal: 7m 1s\tremaining: 3m 30s\n",
      "2100:\tlearn: 0.4987835\ttest: 0.5086905\tbest: 0.5086886 (2098)\ttotal: 7m 27s\tremaining: 3m 11s\n",
      "2200:\tlearn: 0.4983004\ttest: 0.5086871\tbest: 0.5086826 (2183)\ttotal: 7m 56s\tremaining: 2m 52s\n",
      "2300:\tlearn: 0.4978175\ttest: 0.5086664\tbest: 0.5086638 (2298)\ttotal: 8m 31s\tremaining: 2m 35s\n",
      "2400:\tlearn: 0.4973442\ttest: 0.5086382\tbest: 0.5086370 (2397)\ttotal: 9m 8s\tremaining: 2m 16s\n",
      "2500:\tlearn: 0.4968779\ttest: 0.5086303\tbest: 0.5086279 (2466)\ttotal: 9m 34s\tremaining: 1m 54s\n",
      "2600:\tlearn: 0.4964171\ttest: 0.5086298\tbest: 0.5086270 (2531)\ttotal: 10m 3s\tremaining: 1m 32s\n",
      "2700:\tlearn: 0.4959540\ttest: 0.5086216\tbest: 0.5086194 (2699)\ttotal: 10m 30s\tremaining: 1m 9s\n",
      "2800:\tlearn: 0.4954890\ttest: 0.5086189\tbest: 0.5086100 (2790)\ttotal: 10m 58s\tremaining: 46.8s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.5086099659\n",
      "bestIteration = 2790\n",
      "\n",
      "Shrink model to first 2791 iterations.\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_2_CatBoost =====\n",
      "\n",
      "0:\tlearn: 0.6738207\ttest: 0.6738627\tbest: 0.6738627 (0)\ttotal: 244ms\tremaining: 12m 10s\n",
      "100:\tlearn: 0.5115096\ttest: 0.5125153\tbest: 0.5125153 (100)\ttotal: 21.7s\tremaining: 10m 23s\n",
      "200:\tlearn: 0.5101297\ttest: 0.5115249\tbest: 0.5115249 (200)\ttotal: 41.9s\tremaining: 9m 43s\n",
      "300:\tlearn: 0.5091202\ttest: 0.5108836\tbest: 0.5108836 (300)\ttotal: 1m 1s\tremaining: 9m 8s\n",
      "400:\tlearn: 0.5081924\ttest: 0.5104173\tbest: 0.5104173 (400)\ttotal: 1m 27s\tremaining: 9m 26s\n",
      "500:\tlearn: 0.5073966\ttest: 0.5101134\tbest: 0.5101134 (500)\ttotal: 1m 51s\tremaining: 9m 14s\n",
      "600:\tlearn: 0.5066752\ttest: 0.5098958\tbest: 0.5098958 (600)\ttotal: 2m 9s\tremaining: 8m 35s\n",
      "700:\tlearn: 0.5060168\ttest: 0.5097142\tbest: 0.5097142 (700)\ttotal: 2m 28s\tremaining: 8m 5s\n",
      "800:\tlearn: 0.5054170\ttest: 0.5095658\tbest: 0.5095658 (800)\ttotal: 2m 46s\tremaining: 7m 37s\n",
      "900:\tlearn: 0.5048297\ttest: 0.5094945\tbest: 0.5094945 (900)\ttotal: 3m 4s\tremaining: 7m 10s\n",
      "1000:\tlearn: 0.5042670\ttest: 0.5093899\tbest: 0.5093899 (1000)\ttotal: 3m 24s\tremaining: 6m 48s\n",
      "1100:\tlearn: 0.5037204\ttest: 0.5093661\tbest: 0.5093600 (1091)\ttotal: 3m 44s\tremaining: 6m 27s\n",
      "1200:\tlearn: 0.5031935\ttest: 0.5093033\tbest: 0.5093013 (1196)\ttotal: 4m 9s\tremaining: 6m 14s\n",
      "1300:\tlearn: 0.5026561\ttest: 0.5092653\tbest: 0.5092653 (1300)\ttotal: 4m 32s\tremaining: 5m 55s\n",
      "1400:\tlearn: 0.5021325\ttest: 0.5092019\tbest: 0.5091997 (1397)\ttotal: 4m 52s\tremaining: 5m 34s\n",
      "1500:\tlearn: 0.5016343\ttest: 0.5091654\tbest: 0.5091606 (1493)\ttotal: 5m 12s\tremaining: 5m 12s\n",
      "1600:\tlearn: 0.5011386\ttest: 0.5091394\tbest: 0.5091387 (1592)\ttotal: 5m 33s\tremaining: 4m 51s\n",
      "1700:\tlearn: 0.5006457\ttest: 0.5091146\tbest: 0.5091136 (1699)\ttotal: 5m 54s\tremaining: 4m 30s\n",
      "1800:\tlearn: 0.5001554\ttest: 0.5090823\tbest: 0.5090823 (1800)\ttotal: 6m 14s\tremaining: 4m 9s\n",
      "1900:\tlearn: 0.4996767\ttest: 0.5090527\tbest: 0.5090521 (1894)\ttotal: 6m 35s\tremaining: 3m 48s\n",
      "2000:\tlearn: 0.4991855\ttest: 0.5090226\tbest: 0.5090226 (2000)\ttotal: 6m 55s\tremaining: 3m 27s\n",
      "2100:\tlearn: 0.4987092\ttest: 0.5090220\tbest: 0.5090151 (2087)\ttotal: 7m 15s\tremaining: 3m 6s\n",
      "2200:\tlearn: 0.4982406\ttest: 0.5090134\tbest: 0.5090066 (2142)\ttotal: 7m 36s\tremaining: 2m 45s\n",
      "2300:\tlearn: 0.4977719\ttest: 0.5089804\tbest: 0.5089795 (2298)\ttotal: 7m 56s\tremaining: 2m 24s\n",
      "2400:\tlearn: 0.4972959\ttest: 0.5089582\tbest: 0.5089582 (2400)\ttotal: 8m 17s\tremaining: 2m 4s\n",
      "2500:\tlearn: 0.4968245\ttest: 0.5089378\tbest: 0.5089360 (2497)\ttotal: 8m 37s\tremaining: 1m 43s\n",
      "2600:\tlearn: 0.4963719\ttest: 0.5089109\tbest: 0.5089102 (2590)\ttotal: 8m 58s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.4959083\ttest: 0.5089056\tbest: 0.5088978 (2624)\ttotal: 9m 18s\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.5088977583\n",
      "bestIteration = 2624\n",
      "\n",
      "Shrink model to first 2625 iterations.\n",
      "Lvl_0_Pipe_0_Mod_2_CatBoost fitting and predicting completed\n",
      "Optuna may run 1 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 0.6738596\ttest: 0.6738307\tbest: 0.6738307 (0)\ttotal: 211ms\tremaining: 10m 31s\n",
      "100:\tlearn: 0.5120757\ttest: 0.5118526\tbest: 0.5118526 (100)\ttotal: 20.4s\tremaining: 9m 44s\n",
      "200:\tlearn: 0.5108434\ttest: 0.5108802\tbest: 0.5108802 (200)\ttotal: 37.7s\tremaining: 8m 44s\n",
      "300:\tlearn: 0.5100087\ttest: 0.5102441\tbest: 0.5102441 (300)\ttotal: 55.4s\tremaining: 8m 17s\n",
      "400:\tlearn: 0.5092774\ttest: 0.5097864\tbest: 0.5097864 (400)\ttotal: 1m 18s\tremaining: 8m 27s\n",
      "500:\tlearn: 0.5086917\ttest: 0.5094356\tbest: 0.5094356 (500)\ttotal: 1m 35s\tremaining: 7m 57s\n",
      "600:\tlearn: 0.5081926\ttest: 0.5091718\tbest: 0.5091718 (600)\ttotal: 1m 55s\tremaining: 7m 39s\n",
      "700:\tlearn: 0.5077396\ttest: 0.5089808\tbest: 0.5089808 (700)\ttotal: 2m 16s\tremaining: 7m 26s\n",
      "800:\tlearn: 0.5073154\ttest: 0.5087896\tbest: 0.5087896 (800)\ttotal: 2m 36s\tremaining: 7m 9s\n",
      "900:\tlearn: 0.5069165\ttest: 0.5086762\tbest: 0.5086762 (900)\ttotal: 2m 54s\tremaining: 6m 47s\n",
      "1000:\tlearn: 0.5065321\ttest: 0.5085563\tbest: 0.5085563 (1000)\ttotal: 3m 13s\tremaining: 6m 25s\n",
      "1100:\tlearn: 0.5061614\ttest: 0.5084590\tbest: 0.5084590 (1099)\ttotal: 3m 32s\tremaining: 6m 7s\n",
      "1200:\tlearn: 0.5058149\ttest: 0.5083631\tbest: 0.5083631 (1200)\ttotal: 3m 53s\tremaining: 5m 49s\n",
      "1300:\tlearn: 0.5054780\ttest: 0.5082800\tbest: 0.5082800 (1300)\ttotal: 4m 17s\tremaining: 5m 36s\n",
      "1400:\tlearn: 0.5051488\ttest: 0.5081952\tbest: 0.5081952 (1400)\ttotal: 4m 36s\tremaining: 5m 15s\n",
      "1500:\tlearn: 0.5048271\ttest: 0.5081348\tbest: 0.5081348 (1500)\ttotal: 4m 59s\tremaining: 4m 59s\n",
      "1600:\tlearn: 0.5045179\ttest: 0.5080992\tbest: 0.5080992 (1600)\ttotal: 5m 16s\tremaining: 4m 36s\n",
      "1700:\tlearn: 0.5042141\ttest: 0.5080643\tbest: 0.5080643 (1700)\ttotal: 5m 33s\tremaining: 4m 14s\n",
      "1800:\tlearn: 0.5039077\ttest: 0.5080193\tbest: 0.5080189 (1799)\ttotal: 5m 54s\tremaining: 3m 55s\n",
      "1900:\tlearn: 0.5036079\ttest: 0.5079766\tbest: 0.5079766 (1900)\ttotal: 6m 18s\tremaining: 3m 39s\n",
      "2000:\tlearn: 0.5033111\ttest: 0.5079417\tbest: 0.5079363 (1989)\ttotal: 6m 37s\tremaining: 3m 18s\n",
      "2100:\tlearn: 0.5030195\ttest: 0.5079188\tbest: 0.5079170 (2098)\ttotal: 6m 59s\tremaining: 2m 59s\n",
      "2200:\tlearn: 0.5027367\ttest: 0.5078888\tbest: 0.5078888 (2200)\ttotal: 7m 18s\tremaining: 2m 39s\n",
      "2300:\tlearn: 0.5024499\ttest: 0.5078576\tbest: 0.5078554 (2297)\ttotal: 7m 39s\tremaining: 2m 19s\n",
      "2400:\tlearn: 0.5021696\ttest: 0.5078464\tbest: 0.5078406 (2350)\ttotal: 8m 5s\tremaining: 2m 1s\n",
      "2500:\tlearn: 0.5018967\ttest: 0.5078158\tbest: 0.5078158 (2500)\ttotal: 8m 33s\tremaining: 1m 42s\n",
      "2600:\tlearn: 0.5016165\ttest: 0.5077906\tbest: 0.5077896 (2598)\ttotal: 8m 58s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.5013392\ttest: 0.5077585\tbest: 0.5077585 (2700)\ttotal: 9m 24s\tremaining: 1m 2s\n",
      "2800:\tlearn: 0.5010711\ttest: 0.5077427\tbest: 0.5077416 (2781)\ttotal: 9m 46s\tremaining: 41.7s\n",
      "2900:\tlearn: 0.5007964\ttest: 0.5077417\tbest: 0.5077381 (2851)\ttotal: 10m 5s\tremaining: 20.7s\n",
      "2999:\tlearn: 0.5005304\ttest: 0.5077222\tbest: 0.5077222 (2999)\ttotal: 10m 26s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5077222164\n",
      "bestIteration = 2999\n",
      "\n",
      "Lvl_0_Pipe_0_Mod_3_CatBoost fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_0_Mod_3_CatBoost ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 0.6814303\ttest: 0.6814129\tbest: 0.6814129 (0)\ttotal: 373ms\tremaining: 18m 39s\n",
      "100:\tlearn: 0.5131695\ttest: 0.5128056\tbest: 0.5128056 (100)\ttotal: 21.8s\tremaining: 10m 25s\n",
      "200:\tlearn: 0.5117528\ttest: 0.5115709\tbest: 0.5115709 (200)\ttotal: 39.7s\tremaining: 9m 12s\n",
      "300:\tlearn: 0.5110617\ttest: 0.5110232\tbest: 0.5110232 (300)\ttotal: 56.9s\tremaining: 8m 30s\n",
      "400:\tlearn: 0.5105331\ttest: 0.5106209\tbest: 0.5106209 (400)\ttotal: 1m 16s\tremaining: 8m 14s\n",
      "500:\tlearn: 0.5100406\ttest: 0.5102552\tbest: 0.5102552 (500)\ttotal: 1m 37s\tremaining: 8m 5s\n",
      "600:\tlearn: 0.5095674\ttest: 0.5099426\tbest: 0.5099426 (600)\ttotal: 1m 57s\tremaining: 7m 50s\n",
      "700:\tlearn: 0.5091722\ttest: 0.5096968\tbest: 0.5096967 (699)\ttotal: 2m 16s\tremaining: 7m 28s\n",
      "800:\tlearn: 0.5088083\ttest: 0.5094781\tbest: 0.5094781 (800)\ttotal: 2m 34s\tremaining: 7m 5s\n",
      "900:\tlearn: 0.5084802\ttest: 0.5092964\tbest: 0.5092964 (900)\ttotal: 2m 55s\tremaining: 6m 49s\n",
      "1000:\tlearn: 0.5081792\ttest: 0.5091444\tbest: 0.5091444 (1000)\ttotal: 3m 20s\tremaining: 6m 40s\n",
      "1100:\tlearn: 0.5078969\ttest: 0.5090099\tbest: 0.5090099 (1100)\ttotal: 3m 56s\tremaining: 6m 47s\n",
      "1200:\tlearn: 0.5076268\ttest: 0.5088902\tbest: 0.5088901 (1199)\ttotal: 4m 22s\tremaining: 6m 33s\n",
      "1300:\tlearn: 0.5073660\ttest: 0.5087834\tbest: 0.5087834 (1300)\ttotal: 4m 50s\tremaining: 6m 19s\n",
      "1400:\tlearn: 0.5071229\ttest: 0.5086921\tbest: 0.5086921 (1400)\ttotal: 5m 14s\tremaining: 5m 59s\n",
      "1500:\tlearn: 0.5068879\ttest: 0.5086076\tbest: 0.5086076 (1500)\ttotal: 5m 39s\tremaining: 5m 38s\n",
      "1600:\tlearn: 0.5066617\ttest: 0.5085292\tbest: 0.5085292 (1600)\ttotal: 6m 5s\tremaining: 5m 19s\n",
      "1700:\tlearn: 0.5064440\ttest: 0.5084615\tbest: 0.5084615 (1700)\ttotal: 6m 26s\tremaining: 4m 55s\n",
      "1800:\tlearn: 0.5062264\ttest: 0.5084006\tbest: 0.5084006 (1799)\ttotal: 6m 44s\tremaining: 4m 29s\n",
      "1900:\tlearn: 0.5060151\ttest: 0.5083478\tbest: 0.5083478 (1900)\ttotal: 7m 1s\tremaining: 4m 3s\n",
      "2000:\tlearn: 0.5058081\ttest: 0.5082952\tbest: 0.5082952 (2000)\ttotal: 7m 20s\tremaining: 3m 39s\n",
      "2100:\tlearn: 0.5056035\ttest: 0.5082417\tbest: 0.5082407 (2098)\ttotal: 7m 39s\tremaining: 3m 16s\n",
      "2200:\tlearn: 0.5054047\ttest: 0.5081899\tbest: 0.5081894 (2198)\ttotal: 8m 2s\tremaining: 2m 55s\n",
      "2300:\tlearn: 0.5052071\ttest: 0.5081530\tbest: 0.5081529 (2298)\ttotal: 8m 23s\tremaining: 2m 32s\n",
      "2400:\tlearn: 0.5050145\ttest: 0.5081186\tbest: 0.5081178 (2397)\ttotal: 8m 44s\tremaining: 2m 10s\n",
      "2500:\tlearn: 0.5048229\ttest: 0.5080800\tbest: 0.5080800 (2500)\ttotal: 9m 5s\tremaining: 1m 48s\n",
      "2600:\tlearn: 0.5046388\ttest: 0.5080402\tbest: 0.5080394 (2599)\ttotal: 9m 26s\tremaining: 1m 26s\n",
      "2700:\tlearn: 0.5044540\ttest: 0.5080048\tbest: 0.5080048 (2700)\ttotal: 9m 45s\tremaining: 1m 4s\n",
      "2800:\tlearn: 0.5042712\ttest: 0.5079774\tbest: 0.5079774 (2800)\ttotal: 10m 5s\tremaining: 43s\n",
      "2900:\tlearn: 0.5040954\ttest: 0.5079519\tbest: 0.5079519 (2900)\ttotal: 10m 24s\tremaining: 21.3s\n",
      "2999:\tlearn: 0.5039178\ttest: 0.5079297\tbest: 0.5079292 (2992)\ttotal: 10m 43s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5079291554\n",
      "bestIteration = 2992\n",
      "\n",
      "Shrink model to first 2993 iterations.\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 0.6814393\ttest: 0.6814018\tbest: 0.6814018 (0)\ttotal: 215ms\tremaining: 10m 45s\n",
      "100:\tlearn: 0.5133312\ttest: 0.5123449\tbest: 0.5123449 (100)\ttotal: 21.8s\tremaining: 10m 25s\n",
      "200:\tlearn: 0.5119839\ttest: 0.5109884\tbest: 0.5109884 (200)\ttotal: 42.1s\tremaining: 9m 46s\n",
      "300:\tlearn: 0.5112948\ttest: 0.5103773\tbest: 0.5103773 (300)\ttotal: 1m 1s\tremaining: 9m 10s\n",
      "400:\tlearn: 0.5107660\ttest: 0.5099160\tbest: 0.5099160 (400)\ttotal: 1m 22s\tremaining: 8m 51s\n",
      "500:\tlearn: 0.5102915\ttest: 0.5095290\tbest: 0.5095290 (500)\ttotal: 1m 50s\tremaining: 9m 10s\n",
      "600:\tlearn: 0.5098197\ttest: 0.5091764\tbest: 0.5091764 (600)\ttotal: 2m 12s\tremaining: 8m 49s\n",
      "700:\tlearn: 0.5094234\ttest: 0.5089038\tbest: 0.5089038 (700)\ttotal: 2m 31s\tremaining: 8m 16s\n",
      "800:\tlearn: 0.5090619\ttest: 0.5086793\tbest: 0.5086793 (800)\ttotal: 2m 51s\tremaining: 7m 50s\n",
      "900:\tlearn: 0.5087303\ttest: 0.5084931\tbest: 0.5084931 (900)\ttotal: 3m 12s\tremaining: 7m 28s\n",
      "1000:\tlearn: 0.5084277\ttest: 0.5083403\tbest: 0.5083403 (1000)\ttotal: 3m 31s\tremaining: 7m 3s\n",
      "1100:\tlearn: 0.5081519\ttest: 0.5082087\tbest: 0.5082087 (1100)\ttotal: 3m 53s\tremaining: 6m 43s\n",
      "1200:\tlearn: 0.5078825\ttest: 0.5080766\tbest: 0.5080766 (1200)\ttotal: 4m 12s\tremaining: 6m 18s\n",
      "1300:\tlearn: 0.5076263\ttest: 0.5079680\tbest: 0.5079677 (1297)\ttotal: 4m 32s\tremaining: 5m 55s\n",
      "1400:\tlearn: 0.5073877\ttest: 0.5078795\tbest: 0.5078795 (1400)\ttotal: 4m 49s\tremaining: 5m 30s\n",
      "1500:\tlearn: 0.5071526\ttest: 0.5078010\tbest: 0.5078010 (1500)\ttotal: 5m 8s\tremaining: 5m 7s\n",
      "1600:\tlearn: 0.5069267\ttest: 0.5077212\tbest: 0.5077212 (1600)\ttotal: 5m 34s\tremaining: 4m 52s\n",
      "1700:\tlearn: 0.5067060\ttest: 0.5076487\tbest: 0.5076487 (1700)\ttotal: 5m 55s\tremaining: 4m 31s\n",
      "1800:\tlearn: 0.5064908\ttest: 0.5075731\tbest: 0.5075731 (1800)\ttotal: 6m 14s\tremaining: 4m 9s\n",
      "1900:\tlearn: 0.5062772\ttest: 0.5075182\tbest: 0.5075176 (1898)\ttotal: 6m 32s\tremaining: 3m 46s\n",
      "2000:\tlearn: 0.5060738\ttest: 0.5074586\tbest: 0.5074586 (2000)\ttotal: 6m 51s\tremaining: 3m 25s\n",
      "2100:\tlearn: 0.5058708\ttest: 0.5074125\tbest: 0.5074125 (2100)\ttotal: 7m 12s\tremaining: 3m 4s\n",
      "2200:\tlearn: 0.5056689\ttest: 0.5073541\tbest: 0.5073541 (2200)\ttotal: 7m 34s\tremaining: 2m 44s\n",
      "2300:\tlearn: 0.5054748\ttest: 0.5073052\tbest: 0.5073050 (2299)\ttotal: 7m 53s\tremaining: 2m 23s\n",
      "2400:\tlearn: 0.5052854\ttest: 0.5072668\tbest: 0.5072668 (2400)\ttotal: 8m 14s\tremaining: 2m 3s\n",
      "2500:\tlearn: 0.5050900\ttest: 0.5072116\tbest: 0.5072116 (2500)\ttotal: 8m 39s\tremaining: 1m 43s\n",
      "2600:\tlearn: 0.5048961\ttest: 0.5071835\tbest: 0.5071822 (2592)\ttotal: 8m 57s\tremaining: 1m 22s\n",
      "2700:\tlearn: 0.5047123\ttest: 0.5071560\tbest: 0.5071549 (2695)\ttotal: 9m 14s\tremaining: 1m 1s\n",
      "2800:\tlearn: 0.5045282\ttest: 0.5071246\tbest: 0.5071245 (2798)\ttotal: 9m 32s\tremaining: 40.7s\n",
      "2900:\tlearn: 0.5043435\ttest: 0.5070874\tbest: 0.5070872 (2891)\ttotal: 9m 49s\tremaining: 20.1s\n",
      "2999:\tlearn: 0.5041633\ttest: 0.5070601\tbest: 0.5070589 (2994)\ttotal: 10m 7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5070588797\n",
      "bestIteration = 2994\n",
      "\n",
      "Shrink model to first 2995 iterations.\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 0.6814273\ttest: 0.6814344\tbest: 0.6814344 (0)\ttotal: 217ms\tremaining: 10m 50s\n",
      "100:\tlearn: 0.5131520\ttest: 0.5132152\tbest: 0.5132152 (100)\ttotal: 24.5s\tremaining: 11m 42s\n",
      "200:\tlearn: 0.5117334\ttest: 0.5118720\tbest: 0.5118720 (200)\ttotal: 43.2s\tremaining: 10m 1s\n",
      "300:\tlearn: 0.5110372\ttest: 0.5112993\tbest: 0.5112993 (300)\ttotal: 1m 2s\tremaining: 9m 18s\n",
      "400:\tlearn: 0.5105080\ttest: 0.5108932\tbest: 0.5108932 (400)\ttotal: 1m 21s\tremaining: 8m 48s\n",
      "500:\tlearn: 0.5100016\ttest: 0.5105049\tbest: 0.5105049 (500)\ttotal: 1m 39s\tremaining: 8m 17s\n",
      "600:\tlearn: 0.5095200\ttest: 0.5101616\tbest: 0.5101616 (600)\ttotal: 1m 58s\tremaining: 7m 52s\n",
      "700:\tlearn: 0.5091106\ttest: 0.5099028\tbest: 0.5099028 (700)\ttotal: 2m 17s\tremaining: 7m 31s\n",
      "800:\tlearn: 0.5087450\ttest: 0.5096848\tbest: 0.5096848 (800)\ttotal: 2m 36s\tremaining: 7m 9s\n",
      "900:\tlearn: 0.5084171\ttest: 0.5095050\tbest: 0.5095050 (900)\ttotal: 2m 56s\tremaining: 6m 52s\n",
      "1000:\tlearn: 0.5081130\ttest: 0.5093585\tbest: 0.5093585 (1000)\ttotal: 3m 15s\tremaining: 6m 30s\n",
      "1100:\tlearn: 0.5078254\ttest: 0.5092194\tbest: 0.5092194 (1100)\ttotal: 3m 35s\tremaining: 6m 11s\n",
      "1200:\tlearn: 0.5075532\ttest: 0.5091040\tbest: 0.5091040 (1200)\ttotal: 3m 56s\tremaining: 5m 54s\n",
      "1300:\tlearn: 0.5073052\ttest: 0.5090042\tbest: 0.5090042 (1300)\ttotal: 4m 14s\tremaining: 5m 32s\n",
      "1400:\tlearn: 0.5070556\ttest: 0.5089257\tbest: 0.5089257 (1400)\ttotal: 4m 33s\tremaining: 5m 12s\n",
      "1500:\tlearn: 0.5068181\ttest: 0.5088517\tbest: 0.5088517 (1500)\ttotal: 4m 52s\tremaining: 4m 52s\n",
      "1600:\tlearn: 0.5065916\ttest: 0.5087835\tbest: 0.5087835 (1600)\ttotal: 5m 13s\tremaining: 4m 33s\n",
      "1700:\tlearn: 0.5063695\ttest: 0.5087135\tbest: 0.5087133 (1699)\ttotal: 5m 32s\tremaining: 4m 13s\n",
      "1800:\tlearn: 0.5061505\ttest: 0.5086409\tbest: 0.5086409 (1800)\ttotal: 5m 50s\tremaining: 3m 53s\n",
      "1900:\tlearn: 0.5059377\ttest: 0.5085935\tbest: 0.5085931 (1899)\ttotal: 6m 12s\tremaining: 3m 35s\n",
      "2000:\tlearn: 0.5057280\ttest: 0.5085467\tbest: 0.5085467 (2000)\ttotal: 6m 39s\tremaining: 3m 19s\n",
      "2100:\tlearn: 0.5055212\ttest: 0.5085001\tbest: 0.5084994 (2093)\ttotal: 7m\tremaining: 2m 59s\n",
      "2200:\tlearn: 0.5053246\ttest: 0.5084634\tbest: 0.5084634 (2200)\ttotal: 7m 23s\tremaining: 2m 40s\n",
      "2300:\tlearn: 0.5051266\ttest: 0.5084276\tbest: 0.5084276 (2300)\ttotal: 7m 44s\tremaining: 2m 20s\n",
      "2400:\tlearn: 0.5049307\ttest: 0.5083853\tbest: 0.5083848 (2399)\ttotal: 8m 3s\tremaining: 2m\n",
      "2500:\tlearn: 0.5047380\ttest: 0.5083381\tbest: 0.5083379 (2499)\ttotal: 8m 21s\tremaining: 1m 40s\n",
      "2600:\tlearn: 0.5045536\ttest: 0.5083111\tbest: 0.5083111 (2600)\ttotal: 8m 42s\tremaining: 1m 20s\n",
      "2700:\tlearn: 0.5043648\ttest: 0.5082879\tbest: 0.5082879 (2700)\ttotal: 9m 3s\tremaining: 1m\n",
      "2800:\tlearn: 0.5041769\ttest: 0.5082554\tbest: 0.5082554 (2800)\ttotal: 9m 23s\tremaining: 40s\n",
      "2900:\tlearn: 0.5039951\ttest: 0.5082344\tbest: 0.5082340 (2895)\ttotal: 9m 43s\tremaining: 19.9s\n",
      "2999:\tlearn: 0.5038190\ttest: 0.5082089\tbest: 0.5082086 (2997)\ttotal: 10m 3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5082086104\n",
      "bestIteration = 2997\n",
      "\n",
      "Shrink model to first 2998 iterations.\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 0.6814094\ttest: 0.6814350\tbest: 0.6814350 (0)\ttotal: 319ms\tremaining: 15m 57s\n",
      "100:\tlearn: 0.5129221\ttest: 0.5137953\tbest: 0.5137953 (100)\ttotal: 26.4s\tremaining: 12m 37s\n",
      "200:\tlearn: 0.5115522\ttest: 0.5125100\tbest: 0.5125100 (200)\ttotal: 45.6s\tremaining: 10m 34s\n",
      "300:\tlearn: 0.5108670\ttest: 0.5119023\tbest: 0.5119023 (300)\ttotal: 1m 6s\tremaining: 9m 56s\n",
      "400:\tlearn: 0.5103287\ttest: 0.5114644\tbest: 0.5114644 (400)\ttotal: 1m 25s\tremaining: 9m 14s\n",
      "500:\tlearn: 0.5098109\ttest: 0.5110504\tbest: 0.5110504 (500)\ttotal: 1m 46s\tremaining: 8m 50s\n",
      "600:\tlearn: 0.5093633\ttest: 0.5107324\tbest: 0.5107324 (600)\ttotal: 2m 8s\tremaining: 8m 34s\n",
      "700:\tlearn: 0.5089642\ttest: 0.5104763\tbest: 0.5104763 (700)\ttotal: 2m 28s\tremaining: 8m 5s\n",
      "800:\tlearn: 0.5086107\ttest: 0.5102648\tbest: 0.5102648 (800)\ttotal: 2m 45s\tremaining: 7m 34s\n",
      "900:\tlearn: 0.5082869\ttest: 0.5100809\tbest: 0.5100809 (900)\ttotal: 3m 5s\tremaining: 7m 12s\n",
      "1000:\tlearn: 0.5079947\ttest: 0.5099253\tbest: 0.5099253 (999)\ttotal: 3m 22s\tremaining: 6m 44s\n",
      "1100:\tlearn: 0.5077087\ttest: 0.5097805\tbest: 0.5097805 (1100)\ttotal: 3m 40s\tremaining: 6m 20s\n",
      "1200:\tlearn: 0.5074354\ttest: 0.5096619\tbest: 0.5096619 (1200)\ttotal: 3m 58s\tremaining: 5m 56s\n",
      "1300:\tlearn: 0.5071808\ttest: 0.5095606\tbest: 0.5095606 (1300)\ttotal: 4m 16s\tremaining: 5m 34s\n",
      "1400:\tlearn: 0.5069398\ttest: 0.5094901\tbest: 0.5094901 (1399)\ttotal: 4m 33s\tremaining: 5m 12s\n",
      "1500:\tlearn: 0.5067027\ttest: 0.5094157\tbest: 0.5094157 (1500)\ttotal: 4m 51s\tremaining: 4m 50s\n",
      "1600:\tlearn: 0.5064720\ttest: 0.5093344\tbest: 0.5093344 (1600)\ttotal: 5m 9s\tremaining: 4m 30s\n",
      "1700:\tlearn: 0.5062519\ttest: 0.5092692\tbest: 0.5092692 (1700)\ttotal: 5m 27s\tremaining: 4m 10s\n",
      "1800:\tlearn: 0.5060342\ttest: 0.5092124\tbest: 0.5092124 (1800)\ttotal: 5m 46s\tremaining: 3m 50s\n",
      "1900:\tlearn: 0.5058215\ttest: 0.5091608\tbest: 0.5091608 (1900)\ttotal: 6m 6s\tremaining: 3m 31s\n",
      "2000:\tlearn: 0.5056129\ttest: 0.5091112\tbest: 0.5091112 (2000)\ttotal: 6m 25s\tremaining: 3m 12s\n",
      "2100:\tlearn: 0.5054062\ttest: 0.5090600\tbest: 0.5090600 (2100)\ttotal: 6m 43s\tremaining: 2m 52s\n",
      "2200:\tlearn: 0.5052029\ttest: 0.5090192\tbest: 0.5090192 (2200)\ttotal: 7m 1s\tremaining: 2m 33s\n",
      "2300:\tlearn: 0.5050093\ttest: 0.5089822\tbest: 0.5089809 (2291)\ttotal: 7m 33s\tremaining: 2m 17s\n",
      "2400:\tlearn: 0.5048144\ttest: 0.5089509\tbest: 0.5089509 (2400)\ttotal: 7m 54s\tremaining: 1m 58s\n",
      "2500:\tlearn: 0.5046198\ttest: 0.5089077\tbest: 0.5089072 (2499)\ttotal: 8m 15s\tremaining: 1m 38s\n",
      "2600:\tlearn: 0.5044309\ttest: 0.5088750\tbest: 0.5088750 (2600)\ttotal: 8m 36s\tremaining: 1m 19s\n",
      "2700:\tlearn: 0.5042485\ttest: 0.5088357\tbest: 0.5088357 (2700)\ttotal: 8m 57s\tremaining: 59.5s\n",
      "2800:\tlearn: 0.5040605\ttest: 0.5088046\tbest: 0.5088045 (2799)\ttotal: 9m 19s\tremaining: 39.7s\n",
      "2900:\tlearn: 0.5038731\ttest: 0.5087777\tbest: 0.5087762 (2894)\ttotal: 9m 47s\tremaining: 20s\n",
      "2999:\tlearn: 0.5036936\ttest: 0.5087583\tbest: 0.5087568 (2986)\ttotal: 10m 14s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5087568269\n",
      "bestIteration = 2986\n",
      "\n",
      "Shrink model to first 2987 iterations.\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_3_CatBoost =====\n",
      "\n",
      "0:\tlearn: 0.6814112\ttest: 0.6814355\tbest: 0.6814355 (0)\ttotal: 262ms\tremaining: 13m 4s\n",
      "100:\tlearn: 0.5129773\ttest: 0.5136944\tbest: 0.5136944 (100)\ttotal: 24.7s\tremaining: 11m 49s\n",
      "200:\tlearn: 0.5115686\ttest: 0.5124855\tbest: 0.5124855 (200)\ttotal: 45.5s\tremaining: 10m 33s\n",
      "300:\tlearn: 0.5108721\ttest: 0.5119357\tbest: 0.5119357 (300)\ttotal: 1m 11s\tremaining: 10m 42s\n",
      "400:\tlearn: 0.5103385\ttest: 0.5115337\tbest: 0.5115337 (400)\ttotal: 1m 34s\tremaining: 10m 13s\n",
      "500:\tlearn: 0.5098324\ttest: 0.5111618\tbest: 0.5111618 (500)\ttotal: 1m 56s\tremaining: 9m 42s\n",
      "600:\tlearn: 0.5093343\ttest: 0.5108186\tbest: 0.5108186 (600)\ttotal: 2m 16s\tremaining: 9m 6s\n",
      "700:\tlearn: 0.5089260\ttest: 0.5105841\tbest: 0.5105841 (700)\ttotal: 2m 36s\tremaining: 8m 33s\n",
      "800:\tlearn: 0.5085605\ttest: 0.5103916\tbest: 0.5103916 (800)\ttotal: 2m 56s\tremaining: 8m 3s\n",
      "900:\tlearn: 0.5082263\ttest: 0.5102271\tbest: 0.5102271 (900)\ttotal: 3m 16s\tremaining: 7m 37s\n",
      "1000:\tlearn: 0.5079094\ttest: 0.5100886\tbest: 0.5100886 (1000)\ttotal: 3m 36s\tremaining: 7m 13s\n",
      "1100:\tlearn: 0.5076218\ttest: 0.5099630\tbest: 0.5099630 (1100)\ttotal: 3m 56s\tremaining: 6m 47s\n",
      "1200:\tlearn: 0.5073459\ttest: 0.5098512\tbest: 0.5098512 (1200)\ttotal: 4m 13s\tremaining: 6m 20s\n",
      "1300:\tlearn: 0.5070860\ttest: 0.5097461\tbest: 0.5097457 (1298)\ttotal: 4m 31s\tremaining: 5m 54s\n",
      "1400:\tlearn: 0.5068356\ttest: 0.5096740\tbest: 0.5096740 (1400)\ttotal: 4m 48s\tremaining: 5m 29s\n",
      "1500:\tlearn: 0.5065993\ttest: 0.5095936\tbest: 0.5095936 (1500)\ttotal: 5m 5s\tremaining: 5m 5s\n",
      "1600:\tlearn: 0.5063652\ttest: 0.5095250\tbest: 0.5095245 (1599)\ttotal: 5m 24s\tremaining: 4m 43s\n",
      "1700:\tlearn: 0.5061441\ttest: 0.5094762\tbest: 0.5094762 (1698)\ttotal: 5m 43s\tremaining: 4m 22s\n",
      "1800:\tlearn: 0.5059304\ttest: 0.5094262\tbest: 0.5094262 (1800)\ttotal: 6m 4s\tremaining: 4m 2s\n",
      "1900:\tlearn: 0.5057133\ttest: 0.5093857\tbest: 0.5093857 (1900)\ttotal: 6m 23s\tremaining: 3m 41s\n",
      "2000:\tlearn: 0.5055106\ttest: 0.5093368\tbest: 0.5093368 (2000)\ttotal: 6m 45s\tremaining: 3m 22s\n",
      "2100:\tlearn: 0.5053084\ttest: 0.5092863\tbest: 0.5092863 (2100)\ttotal: 7m 4s\tremaining: 3m 1s\n",
      "2200:\tlearn: 0.5051061\ttest: 0.5092501\tbest: 0.5092494 (2194)\ttotal: 7m 25s\tremaining: 2m 41s\n",
      "2300:\tlearn: 0.5049112\ttest: 0.5092261\tbest: 0.5092251 (2299)\ttotal: 7m 45s\tremaining: 2m 21s\n",
      "2400:\tlearn: 0.5047214\ttest: 0.5091934\tbest: 0.5091924 (2392)\ttotal: 8m 5s\tremaining: 2m 1s\n",
      "2500:\tlearn: 0.5045270\ttest: 0.5091655\tbest: 0.5091655 (2500)\ttotal: 8m 24s\tremaining: 1m 40s\n",
      "2600:\tlearn: 0.5043439\ttest: 0.5091377\tbest: 0.5091377 (2600)\ttotal: 8m 44s\tremaining: 1m 20s\n",
      "2700:\tlearn: 0.5041587\ttest: 0.5091047\tbest: 0.5091047 (2700)\ttotal: 9m 5s\tremaining: 1m\n",
      "2800:\tlearn: 0.5039696\ttest: 0.5090737\tbest: 0.5090737 (2800)\ttotal: 9m 24s\tremaining: 40.1s\n",
      "2900:\tlearn: 0.5037820\ttest: 0.5090483\tbest: 0.5090451 (2894)\ttotal: 9m 43s\tremaining: 19.9s\n",
      "2999:\tlearn: 0.5035981\ttest: 0.5090257\tbest: 0.5090257 (2999)\ttotal: 10m 2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5090257394\n",
      "bestIteration = 2999\n",
      "\n",
      "Lvl_0_Pipe_0_Mod_3_CatBoost fitting and predicting completed\n",
      "Time left 16464.30728006363\n",
      "Blending: Optimization starts with equal weights and score 0.8149019804053014\n",
      "Blending, iter 0: score = 0.8150248938915031, weights = [0.13448998 0.23765174 0.49246567 0.1353926 ]\n",
      "Blending, iter 1: score = 0.8150253625137595, weights = [0.12863265 0.23990282 0.5048133  0.12665121]\n",
      "Blending, iter 2: score = 0.8150254170211424, weights = [0.12885533 0.23684128 0.5133682  0.12093518]\n",
      "Blending, iter 3: score = 0.8150254280390097, weights = [0.12850639 0.23698619 0.51349825 0.12100917]\n",
      "Blending, iter 4: score = 0.8150254279365685, weights = [0.12846628 0.23699708 0.5135219  0.12101474]\n",
      "\n",
      "Automl preset training completed in 12393.05 seconds.\n",
      "oof_pred:\n",
      "array([[0.6209906 ],\n",
      "       [0.15224761],\n",
      "       [0.7969253 ],\n",
      "       ...,\n",
      "       [0.10170196],\n",
      "       [0.5793944 ],\n",
      "       [0.7701857 ]], dtype=float32)\n",
      "Shape = (957919, 1)\n",
      "Wall time: 3h 26min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "roles = {'target' : 'claim'}\n",
    "\n",
    "automl = TabularAutoML(task = task, \n",
    "                       timeout = TIMEOUT,\n",
    "                       cpu_limit = N_THREADS,\n",
    "                       reader_params = {'n_jobs': N_THREADS, 'random_state': RANDOM_STATE}, # 'cv': N_FOLDS, \n",
    "                       general_params={'use_algos': [['lgb', 'lgb_tuned', 'cb', 'cb_tuned']]}\n",
    "                      )\n",
    "\n",
    "oof_pred = automl.fit_predict(train_data, roles = roles)\n",
    "print('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))\n",
    "\n",
    "# Fast feature importances calculation\n",
    "importances = automl.get_feature_scores('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a8c58f3-3451-4e91-8abc-97ad8b36ea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for te_data:\n",
      "array([[0.58750516],\n",
      "       [0.11969324],\n",
      "       [0.61386937],\n",
      "       ...,\n",
      "       [0.7540916 ],\n",
      "       [0.134525  ],\n",
      "       [0.74502075]], dtype=float32)\n",
      "Shape = (493474, 1)\n"
     ]
    }
   ],
   "source": [
    "test_pred = automl.predict(test_data)\n",
    "print('Prediction for te_data:\\n{}\\nShape = {}'.format(test_pred, test_pred.shape))\n",
    "\n",
    "submission['claim'] = test_pred.data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1eb77ff-d02d-42d6-9cef-00e2ea16cc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>957919</th>\n",
       "      <td>0.587505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957920</th>\n",
       "      <td>0.119693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957921</th>\n",
       "      <td>0.613869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957922</th>\n",
       "      <td>0.132171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957923</th>\n",
       "      <td>0.146169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451388</th>\n",
       "      <td>0.826813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451389</th>\n",
       "      <td>0.113129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451390</th>\n",
       "      <td>0.754092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451391</th>\n",
       "      <td>0.134525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451392</th>\n",
       "      <td>0.745021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493474 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            claim\n",
       "id               \n",
       "957919   0.587505\n",
       "957920   0.119693\n",
       "957921   0.613869\n",
       "957922   0.132171\n",
       "957923   0.146169\n",
       "...           ...\n",
       "1451388  0.826813\n",
       "1451389  0.113129\n",
       "1451390  0.754092\n",
       "1451391  0.134525\n",
       "1451392  0.745021\n",
       "\n",
       "[493474 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f36d5719-6fc0-4526-a642-28c0a450fee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "importances.set_index('Feature')['Importance'].plot.bar()\n",
    "plt.title('Feature importances')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "005c009b-e816-4370-95d1-5cb946b6e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../Submissions/lightautoml_w_nan.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc827ce-3a0e-4e70-9296-9acec3aaf53e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
